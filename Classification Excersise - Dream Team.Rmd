---
title: "Regression"
author: "Ran Dou, Mduduzi Langwenya, Kimo Li, Siyan Lin, Muhammad Furqan Shaikh, Tianyi Zhou"
date: "03/09/2019"
output: html_document
---

### Load the packages
```{r, message=FALSE, warning=FALSE}

rm(list = ls(all = TRUE))
library(tidyverse)
library(forecast)
library(leaps)
library(pROC)
library(reshape)
library(corrplot)
library(broom)
library(caret)
```

### I. Data cleaning and impution

##### Data importing
```{r, warning=FALSE, message=FALSE}
###import the raw diabetes data
diabetes <- read_csv("diabetes.csv")
###delete all the missing valuse
diabetes1 <- diabetes %>%
  filter( Glucose !=0 & BMI != 0 & BloodPressure != 0 & Insulin != 0 & SkinThickness != 0) %>%
  select(Glucose, Insulin, Outcome, BMI, SkinThickness )
```

##### Fill-in Zero Value
###### 1) Insulin
```{r,  message=FALSE}
### Insulin 
# stepwise for choosing models for Insulin 
insu.lm.null <- lm(Insulin~1, data = diabetes1)
insu.lm <- lm(Insulin~., data = diabetes1)
summary(insu.lm.null)
summary(insu.lm)
insu.lm.step_both <- step(insu.lm, direction = "both")
sum_both <- summary(insu.lm.step_both)
### create the model for imputing Insulin missing values
lm.data <- lm (Insulin ~ Glucose + BMI, data=diabetes1)
pred.1 <- predict (lm.data, diabetes1)
impute <-function(a, a.impute){
         ifelse(a$Insulin == 0, round(a.impute, 0), a$Insulin)
}
diabetes$newInsu <- impute(diabetes, pred.1)
rm( insu.lm, insu.lm.null, insu.lm.step_both, sum_both, lm.data)
```

###### 2) Skinthickness 
```{r}
### stepwise for choosing models for Insulin 
skin.lm.null <- lm(SkinThickness~1, data = diabetes1)
skin.lm <- lm(SkinThickness~., data = diabetes1)
skin.lm.step_both <- step(skin.lm, direction = "both")
sum_both_skin <- summary(skin.lm.step_both)
### create the model for imputing SkinThickness missing values
lm2.data <- lm(SkinThickness ~ BMI, data=diabetes1)
pred.2 <- predict (lm2.data, diabetes1)
impute <-function(a, a.impute){
  ifelse(a$SkinThickness == 0, round(a.impute, 0), a$SkinThickness)
}
diabetes$newSkin <- impute(diabetes, pred.2)

rm(skin.lm.null, skin.lm, skin.lm.step_both, sum_both_skin, lm2.data, pred.2,diabetes1)
```

```{r}
################################ logistic regression part #############################
# CHANGE DATA TYPE
diabetes$Outcome <- as.factor(diabetes$Outcome)
diabetes$Pregnancies <- as.factor(diabetes$Pregnancies)
diabetes$Insulin <- NULL
diabetes$SkinThickness <- NULL
diabetes$newSkin <- NULL


# divide data into train and test set
set.seed(1)
randOrder = order(runif(nrow(diabetes)))
train.df = subset(diabetes,randOrder < .8 * nrow(diabetes))
test.df = subset(diabetes,randOrder > .8 * nrow(diabetes))
```

##### correlation matrix

```{r, fig.width=6}
# plot the correlation matrix visual
corr.df <- train.df
corr.df$Outcome <- as.numeric(corr.df$Outcome)
corr.df$Pregnancies <- as.numeric(corr.df$Pregnancies)
cor <- cor(corr.df)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```

```{r}
train.df$Outcome <- as.factor(train.df$Outcome)
train.df$Pregnancies <- as.factor(train.df$Pregnancies)
```

################################################################################################### 

# Logistic Regression

```{r}
### Forward Step-wise
# create model with no predictors for bottom of search range
nothing <- glm(Outcome~1, data = train.df, family = binomial)
fullmod <- glm(Outcome~., data = train.df, family = binomial)

# Backward Step-wise
backwards <- step(fullmod, trace =0); sum_back <- summary(backwards) 

#  forward selection
forward<-step(nothing,list(lower=formula(nothing), upper=formula(fullmod)), direction = "forward", trace = 0)
sum_for <- summary(forward) 

# Both Direction Step-wise
both <- step(fullmod, scope = list(lower=formula(nothing),upper=formula(fullmod)), direction="both",trace=0)
sum_both <- summary(both) 

# best model with aic
sum_for$aic


or <-round(exp(sum_for$coef),4);or
```

```{r, message=FALSE}
#CONFUSION MATRIX 
#load caret library
library(caret)

# Prediction on train data (in-sample) and accuracy test 
logit.reg.train <- predict(forward, newdata = train.df, type = "response")
confusionMatrix(as.factor(ifelse(logit.reg.train > 0.55, 1, 0)), as.factor(train.df$Outcome))

# Prediction on test data (out of sample)and accuracy test
logit.reg.test <- predict(forward, newdata = test.df, type = "response")
confusionMatrix(as.factor(ifelse(logit.reg.test > 0.55, 1, 0)), as.factor(test.df$Outcome))

```


```{r}
#ROC 
test_prob <- predict(forward, newdata = test.df, type = "response")
test_roc <- roc(test.df$Outcome ~ test_prob, plot = TRUE, print.auc = TRUE) # 0.774
```


```{r, fig.width=3}
#Residuals 
model1_data <- augment(forward) %>% 
  mutate(index = 1:n()) %>%
  mutate(Outcome = ifelse(Outcome == "1", "0", "1"))
### Create theme for plots
theme <- theme_test(base_family = "Times New Roman") + theme(plot.title = element_text(hjust = 0.5), 
         legend.position = "bottom", panel.grid.minor = element_blank(), axis.ticks.x = element_blank(),
         axis.ticks.y = element_blank(), panel.grid.major = element_blank())
c <- ggplot(model1_data, aes(index, .std.resid, color = Outcome)) + 
  geom_point(stat = "identity") +
  labs(title = "Standardized Deviance Residuals", y = "Residual Std", x ="Residuals") 
c
```

################################################################################################### 

# Classification Tree

```{r, message=FALSE}
set.seed(1)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
```

```{r}
tree <- rpart(Outcome ~., train.df, method = "class")
fancyRpartPlot(tree)
```

```{r}
tree <- rpart(Survived ~ ., train, method = "class", control = rpart.control(cp=0.00001))
# Draw the complex tree
fancyRpartPlot(tree)
# Prune the tree: pruned
pruned <- prune(tree, cp=0.01)
# Draw pruned
fancyRpartPlot(pruned)
```

```{r}
table(pred=tree.pred, true=test.df$Outcome)
printcp(tree)
# get index of CP with lowest xerror
tree.best <- which.min(tree$cptable[,"xerror"])
# get its value
cp <- tree$cptable[tree.best, "CP"]
cp
plotcp(tree)
```

```{r}
#prune tree
tree.pruned <- prune(tree,cp)
#plot tree
fancyRpartPlot(tree.pruned)
```

```{r}
tree_i <- rpart(spam ~ ., train, method = "class", parms = list(split = "information"))
pred_i <- predict(tree_i, test, type = "class")
conf_i <- table(test$spam, pred_i)
acc_i <- sum(diag(conf_i)) / sum(conf_i)
```

```{r}
tree.pred <- predict(tree, test.df, type="class")
tree.conf <- table(test.df$Outcome, tree.pred)
sum(diag(tree.conf))/sum(tree.conf)
```

```{r}
evaluation <- function(model, data, atype) {
  cat("\nConfusion matrix:\n")
  prediction = predict(model, data, type=atype)
  xtab = table(prediction, data$Outcome)
  print(xtab)
  cat("\nEvaluation:\n\n")
  accuracy = sum(prediction == data$Outcome)/length(data$Outcome)
  precision = xtab[1,1]/sum(xtab[,1])
  recall = xtab[1,1]/sum(xtab[1,])
  f = 2 * (precision * recall) / (precision + recall)
  cat(paste("Accuracy:\t", format(accuracy, digits=2), "\n",sep=" "))
  cat(paste("Precision:\t", format(precision, digits=2), "\n",sep=" "))
  cat(paste("Recall:\t\t", format(recall, digits=2), "\n",sep=" "))
  cat(paste("F-measure:\t", format(f, digits=2), "\n",sep=" "))
}
evaluation(tree, test.df, "class")
```

########################################################################################

### KNN

```{r}
# make dummies
seg.flg.num <- model.matrix(~., data = diabetes)
seg.flg.num <- seg.flg.num [,-1]

# scaling the data
scaled_data <- scale(seg.flg.num)
scaled_data <- as.data.frame(scaled_data) 

randOrder = order(runif(nrow(scaled_data)))
train.df = subset(diabetes,randOrder < .8 * nrow(scaled_data))
test.df = subset(diabetes,randOrder > .8 * nrow(scaled_data))

# initialize a data frame with two columns: k, and accuracy.
accuracy.df <- data.frame(k = seq(1, 14, 1), accuracy = rep(0, 14))
test.df$Outcome <- as.factor(test.df$Outcome)

# compute knn for different k on validation.
for(i in 1:14) {
  knn.pred <- knn(train.df,test.df, train.df$Outcome,k = i)
  accuracy.df[i, 2] <- confusionMatrix(knn.pred, test.df$Outcome)$overall[1]
}
accuracy.df
```









